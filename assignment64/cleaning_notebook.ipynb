{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.   Loading the Dataframe and detecting the missing values such as: (0, \"N/a\", \"na\", np.nan) ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "    #! df = pd.read_csv(url, low_memory=False, na_values = missing_values)\n",
    "    #! Define dtype for columns or use low_memory=False\n",
    "\n",
    "url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/64a26694-01dc-4ec3-aa87-ad8509604f50/resource/1e824947-d73b-4f48-9bac-7f7f3731a6b9/download/Fire%20Incidents%20Data.csv\"\n",
    "missing_values = [\"N/a\", \"na\", np.nan]\n",
    "dtype_dict = {\n",
    "    '_id': int,\n",
    "    'Area_of_Origin': str,\n",
    "    'Building_Status': str,\n",
    "    'Business_Impact': str,\n",
    "    'Civilian_Casualties': float,\n",
    "    'Count_of_Persons_Rescued': float,\n",
    "    'Estimated_Dollar_Loss': float,\n",
    "    'Estimated_Number_Of_Persons_Displaced': float,\n",
    "    'Exposures': float,\n",
    "    'Ext_agent_app_or_defer_time': str,\n",
    "    'Extent_Of_Fire': str,\n",
    "    'Final_Incident_Type': str,\n",
    "    'Fire_Alarm_System_Impact_on_Evacuation': str,\n",
    "    'Fire_Alarm_System_Operation': str,\n",
    "    'Fire_Alarm_System_Presence': str,\n",
    "    'Fire_Under_Control_Time': str,\n",
    "    'Ignition_Source': str,\n",
    "    'Incident_Number': str,\n",
    "    'Incident_Station_Area': str,\n",
    "    'Incident_Ward': float,\n",
    "    'Initial_CAD_Event_Type': str,\n",
    "    'Intersection': str,\n",
    "    'Last_TFS_Unit_Clear_Time': str,\n",
    "    'Latitude': float,\n",
    "    'Level_Of_Origin': str,\n",
    "    'Longitude': float,\n",
    "    'Material_First_Ignited': str,\n",
    "    'Method_Of_Fire_Control': str,\n",
    "    'Number_of_responding_apparatus': float,\n",
    "    'Number_of_responding_personnel': float,\n",
    "    'Possible_Cause': str,\n",
    "    'Property_Use': str,\n",
    "    'Smoke_Alarm_at_Fire_Origin': str,\n",
    "    'Smoke_Alarm_at_Fire_Origin_Alarm_Failure': str,\n",
    "    'Smoke_Alarm_at_Fire_Origin_Alarm_Type': str,\n",
    "    'Smoke_Alarm_Impact_on_Persons_Evacuating_Impact_on_Evacuation': str,\n",
    "    'Smoke_Spread': str,\n",
    "    'Sprinkler_System_Operation': str,\n",
    "    'Sprinkler_System_Presence': str,\n",
    "    'Status_of_Fire_On_Arrival': str,\n",
    "    'TFS_Alarm_Time': str,\n",
    "    'TFS_Arrival_Time': str,\n",
    "    'TFS_Firefighter_Casualties': float\n",
    "}\n",
    "#\n",
    "df = pd.read_csv(url, dtype=dtype_dict, na_values = missing_values)\n",
    "# df = pd.read_csv(url, dtype=dtype_dict)\n",
    "\n",
    "\n",
    "    #? Show missing values\n",
    "# df.isnull().sum()\n",
    "\n",
    "    #? Or in boolean format:\n",
    "# df.isnull().any()\n",
    "\n",
    "    #? Heatmap of missing values\n",
    "# sns.heatmap(df.isnull(), yticklabels=False)\n",
    "# sns.heatmap(df.isnull(), yticklabels=False, annot=True)\n",
    "\n",
    "    #? 29425 rows × 43 columns with NaN\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.   Handling the missing values ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #? Remove only the rows that are all NaN (still 29425 rows × 43 columns, no row has only NaN)\n",
    "df_dropped = df\n",
    "df_dropped = df_dropped.dropna(how=\"all\")\n",
    "\n",
    "\n",
    "    #? Swap all NaN values to '0'\n",
    "df_dropped = df_dropped.fillna(0)\n",
    "# df_dropped.isnull().any()\n",
    "\n",
    "    #? Or swap only one row's NaN's to '0'\n",
    "# df_dropped[\"Area_of_Origin\"] = df_dropped[\"Area_of_Origin\"].fillna(0)\n",
    "# df_dropped.isnull().any()\n",
    "\n",
    "# df_dropped\n",
    "\n",
    "    #? This this allows calculations to be made on that dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.   Handling Duplicates ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #? Check for Duplicates\n",
    "df_dropped.duplicated()\n",
    "\n",
    "    #? Drop all the duplicates (none on this case still 29425 rows × 43 columns)\n",
    "df_dropped.drop_duplicates(keep=\"first\", inplace=True)\n",
    "# df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.   Handling Dates ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['TFS_Alarm_Time', 'Fire_Under_Control_Time', 'Last_TFS_Unit_Clear_Time', 'TFS_Arrival_Time', 'Ext_agent_app_or_defer_time']\n",
    "for col in date_columns:\n",
    "    df_dropped[col] = pd.to_datetime(df_dropped[col], errors='coerce')\n",
    "# df_dropped.info()\n",
    "# df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.   Changing types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_cols = [\"TFS_Firefighter_Casualties\", \"Civilian_Casualties\", \"Count_of_Persons_Rescued\", \"Number_of_responding_personnel\", \"Number_of_responding_apparatus\", \"Exposures\"]\n",
    "df_dropped['Civilian_Casualties'] = df_dropped['Civilian_Casualties'].astype(int)\n",
    "df_dropped['Count_of_Persons_Rescued'] = df_dropped['Count_of_Persons_Rescued'].astype(int)\n",
    "\n",
    "for col in change_cols:\n",
    "    df_dropped[col] = df_dropped[col].astype(int)\n",
    "\n",
    "# df_dropped.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset has been saved to cleaned_fire_incidents.csv\n"
     ]
    }
   ],
   "source": [
    "# # Save the cleaned dataset to a CSV file\n",
    "# cleaned_file_path = 'cleaned_fire_incidents.csv'\n",
    "# df_dropped.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# print(f\"Cleaned dataset has been saved to {cleaned_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
